# A Behavior Modeling and Ensemble Learning–Based Book Recommendation System for University Librariesreaders.

This project implements a personalized recommendation system for university libraries, recommending one book to each user who has borrowed books (Top-1 recommendation).
The system is based on real borrowing logs, through:

1. Collaborative Filtering (CF) generates candidate books
2. Behavioral Feature Modeling (User Profile + Book Profile)
3. Multi-model ensemble learning (XGBoost + CatBoost + MLP fusion)
   A complete offline recommendation system is formed: data preprocessing → candidate generation → feature engineering → model training → fusion weight search → generating recommendation results → F1 evaluation.

## Features

1. Top-1 recommendations for users with interactive content
   Recommendations are generated only for users with borrowing records, and the output consists of two columns: user\_id and book\_id.
2. One-click full-process operation
   A run.bat script is provided, which supports one-click execution in a Windows + Conda environment: preprocessing → training → weight search → prediction → evaluation.
3. Behavioral modeling + collaborative filtering candidate
   Borrowing behavior is used to build user interests, co-occurrence relationships are used to generate a candidate set of CF (College/Grade Popular Books) and then combined with popular books from the college/grade as a backup.
4. Multi-model ensemble learning
   The candidate set is learned and ranked using XGBoost / CatBoost / MLP, and the optimal fusion weights are automatically found through grid search (written to models/blend.json).
5. Offline evaluation closed loop
   Automatically construct data/test.csv as the truth value for "last borrowing", and use evaluate.py to calculate Precision / Recall / F1 to verify the recommendation effect.

## Project Structure

aicProject/
├─ src/
│  ├─ preprocess.py    # Data cleaning and merging, generating data/train.csv
│  ├─ cf.py            # Collaborative filtering candidate generation, output data/cf\_scores.csv
│  ├─ features.py      # Feature engineering, output data/features.csv + feature\_names.json
│  ├─ train.py         # Train XGBoost / CatBoost / MLP models
│  ├─ tune.py          # Search for the optimal fusion weights and write them to models/blend.json
│  ├─ predict.py       # Reads the model and weights, and generates Top-1 recommendations for the target user
│  ├─ evaluate.py      # Use data/test.csv to perform F1 evaluation on the recommendation results
│  └─ utils.py         # General-purpose tools for logging, reading/writing, random seeds, timing, etc.
│
├─ data/
│  ├─ user.csv                 # Reader Information
│  ├─ item.csv                 # Book Information
│  ├─ inter\_preliminary.csv    # Borrowing behavior log (raw interaction data)
│  ├─ train.csv                # Preprocessed interactive + user + book merged table (automatically generated)
│  ├─ test\_users\_all.csv       # Target user list
│  ├─ test.csv                 # The truth set consisting of the last borrowing session
│  ├─ cf\_scores.csv            # Candidates generated by CF (user\_id, book\_id, cf\_score)
│  └─ features.csv             # Candidate feature table (user\_id, book\_id, 10+ feature columns)
│
├─ models/
│  ├─ xgb\_model.json           # XGBoost model
│  ├─ cat\_model.cbm            # CatBoost model
│  ├─ mlp\_model.pkl            # MLP model
│  ├─ mlp\_scaler.pkl           # StandardScaler corresponding to MLP
│  └─ blend.json               # Model fusion weights, for example {"xgb": 0.8, "cat": 0.1, "mlp": 0.1}
│
├─ output/
│  └─ submission.csv           # Final recommendation results (each row contains one user\_id and book\_id)
│
├─ run.bat                     # One-click script execution in Windows environment
├─ requirements.txt  
└─ README.md                   # Documentation

## Data Description

The project uses 3 raw data files by default (located in the data/ directory):
The files data/user.csv (user table), data/item.csv (book table), and data/inter\_preliminary.csv (borrowing behavior log) are also available.

## Environment configuration

Taking Conda as an example:

1. Create a virtual environment
   conda create -n aic python=3.10
   conda activate aic
2. Install relevant libraries
   conda install numpy pandas scipy scikit-learn matplotlib jupyter -y
   pip install xgboost catboost joblib

## Quick Start and Logs

One-click run (Windows)
Ensure the current directory is the project root directory (containing src/ and run.bat) and that the Conda environment is activated:
conda activate aic
cd path/to/aicProject
.\\run.bat

The run.bat file will execute the following commands sequentially:
python -m src.preprocess
python -m src.train
python -m src.tune (automatically searches for the optimal fusion weights)
python -m src.predict
python -m src.evaluate

The terminal will output detailed logs. After the process is complete, the final recommendation results will be in output/submission.csv, in the form of:
user\_id, book\_id
311,25119
466,51572
...
Each user\_id corresponds to at most one recommended book.

